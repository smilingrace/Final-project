{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from astropy.coordinates import SkyCoord\n",
    "from astropy import units as u\n",
    "#conda install -p c:\\Users\\smili\\miniconda3 ipykernel --update-deps --force-reinstall\n",
    "# Load data\n",
    "# cluster_data = pd.read_csv('data/NGC6397-1.dat', delim_whitespace=True, header=None, names=['RA', 'Dec'])\n",
    "gaia_data = pd.read_csv('data/gaia-NGC6397-neighborhood.csv')\n",
    "cluster_data = pd.read_fwf('data/NGC6397-1.dat', colspecs='infer', header=None)\n",
    "# Convert RA and Dec to SkyCoord objects\n",
    "cluster_coords = SkyCoord(ra=cluster_data.iloc[:, -2], dec=cluster_data.iloc[:, -1], unit=(u.hourangle, u.deg))\n",
    "gaia_coords = SkyCoord(ra=gaia_data['ra'], dec=gaia_data['dec'], unit=(u.deg, u.deg))\n",
    "# Cross-match\n",
    "idx, d2d, _ = cluster_coords.match_to_catalog_sky(gaia_coords)\n",
    "max_radius = 1.0 * u.arcsec  # maximum acceptable separation\n",
    "match_mask = d2d < max_radius\n",
    "\n",
    "# Filter matched sources\n",
    "matched_cluster_members = cluster_data[match_mask]\n",
    "matched_gaia_sources = gaia_data.iloc[idx[match_mask]]\n",
    "\n",
    "# Display \n",
    "print(\"Number of matched cluster members:\", len(matched_cluster_members))\n",
    "print(\"Number of matched Gaia sources:\", len(matched_gaia_sources))\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the data\n",
    "data = pd.read_csv('data/gaia-NGC6397-neighborhood.csv')\n",
    "\n",
    "# Display basic statistics\n",
    "print(data.describe())\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(data['ra'], data['dec'], s=1, alpha=0.5)\n",
    "plt.xlabel('Right Ascension (deg)')\n",
    "plt.ylabel('Declination (deg)')\n",
    "plt.title('Scatter Plot: Right Ascension vs Declination')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "#This plot is just a block of noise due to the fact that there are many background stars, and it is a \n",
    "#very wide field of view, I can edit it to be more limited to make the following plot\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(data['ra'], data['dec'], s=1, alpha=0.5)\n",
    "plt.xlim(263, 267)  # Limiting the range of Right Ascension\n",
    "plt.ylim(-54, -52)  # Limiting the range of Declination\n",
    "plt.xlabel('Right Ascension (deg)')\n",
    "plt.ylabel('Declination (deg)')\n",
    "plt.title('Scatter Plot: Right Ascension vs Declination')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "#Here I've added limits, so its a smaller block of noise!\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(data['pmra'], data['pmdec'], s=1, alpha=0.5)\n",
    "plt.xlabel('Proper Motion in RA (mas/yr)')\n",
    "plt.ylabel('Proper Motion in Dec (mas/yr)')\n",
    "plt.title('Scatter Plot: Proper Motion in RA vs Dec')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Histogram of Right Ascension\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.hist(data['ra'], bins=50, color='skyblue', edgecolor='black')\n",
    "plt.xlabel('Right Ascension (deg)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Histogram: Right Ascension')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Histogram of Declination\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.hist(data['dec'], bins=50, color='lightgreen', edgecolor='black')\n",
    "plt.xlabel('Declination (deg)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Histogram: Declination')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Histogram of proper motion in RA\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.hist(data['pmra'], bins=50, color='salmon', edgecolor='black')\n",
    "plt.xlabel('Proper Motion in RA (mas/yr)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Histogram: Proper Motion in RA')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Histogram of proper motion in Dec\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.hist(data['pmdec'], bins=50, color='goldenrod', edgecolor='black')\n",
    "plt.xlabel('Proper Motion in Dec (mas/yr)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Histogram: Proper Motion in Dec')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "#Particular observed quantities that are useful for distinguishing cluster members from background stars include\n",
    "#Positional Measurements: Cluster members might be concentrated around a specific region in the sky (e.g., a \n",
    "#cluster center), while background stars might be more uniformly distributed. Outliers or clusters in the positional \n",
    "#scatter plot could indicate potential cluster members.\n",
    "#Velocity Measurements: Cluster members might exhibit similar proper motions due to their common motion through\n",
    "#space, while background stars might have more varied proper motions. Clustering or distinctive patterns in the \n",
    "#scatter plot of proper motions could indicate potential cluster members.\n",
    "#Histograms: Peaks or distinctive shapes in the histograms of positional or velocity measurements could provide \n",
    "#additional insights into the distribution of cluster members and background stars.\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# # Load the data\n",
    "# data = pd.read_csv('data/gaia-NGC6397-neighborhood.csv')\n",
    "\n",
    "# # Select relevant features (e.g., position and velocity measurements)\n",
    "# X = data[['ra', 'dec', 'pmra', 'pmdec']].values\n",
    "# y = data['NGC6397_member'].values  # Assuming 'member_status' is the correct column name\n",
    "\n",
    "# # Split the data into training and testing sets\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# # Standardize the features (optional, but can improve model performance)\n",
    "# scaler = StandardScaler()\n",
    "# X_train_scaled = scaler.fit_transform(X_train)\n",
    "# X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "# Select relevant features (e.g., position and velocity measurements)\n",
    "X = data[['ra', 'dec', 'pmra', 'pmdec']].values\n",
    "\n",
    "# Initialize DBSCAN clustering algorithm\n",
    "dbscan = DBSCAN(eps=0.5, min_samples=10)\n",
    "\n",
    "# Fit the model to the data\n",
    "dbscan.fit(X)\n",
    "\n",
    "# Get cluster labels\n",
    "cluster_labels = dbscan.labels_\n",
    "\n",
    "# Print the number of clusters (excluding noise points)\n",
    "n_clusters = len(set(cluster_labels)) - (1 if -1 in cluster_labels else 0)\n",
    "print(\"Number of clusters:\", n_clusters)\n",
    "#The above code didnt run due to a KeyError 'NGC6397_member' so I tried the code below to fix it\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Handle missing values\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "X_imputed = imputer.fit_transform(X)\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_imputed)\n",
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "# Initialize DBSCAN clustering algorithm\n",
    "dbscan = DBSCAN(eps=0.5, min_samples=10)\n",
    "\n",
    "# Fit the model to the scaled data\n",
    "dbscan.fit(X_scaled)\n",
    "\n",
    "# Get cluster labels\n",
    "cluster_labels = dbscan.labels_\n",
    "\n",
    "# Print the number of clusters (excluding noise points)\n",
    "n_clusters = len(set(cluster_labels)) - (1 if -1 in cluster_labels else 0)\n",
    "print("Number of clusters:", n_clusters)\n",
     ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot clusters\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(X_scaled[:, 0], X_scaled[:, 1], c=cluster_labels, cmap='viridis', s=10)\n",
    "plt.xlabel('Scaled Right Ascension')\n",
    "plt.ylabel('Scaled Declination')\n",
    "plt.title('DBSCAN Clusters')\n",
    "plt.colorbar(label='Cluster Label')\n",
    "plt.show()\n",
    "#This plot shows up as a wall of noise, I could do the following to fix it:\n",
    "#Parameter Tuning: Experiment with different values for the eps and min_samples\n", 
    "#parameters of the DBSCAN algorithm. Adjusting these parameters can significantly\n", 
    "#impact the clustering results. Try a range of values and observe how they affect the clustering outcome.\n",
    "#Outlier Detection: Identify and remove outliers from the dataset before applying\n", 
    "#the clustering algorithm. Outliers can significantly affect the density estimation\n", 
    "#performed by DBSCAN and lead to noisy clusters. You can use techniques such as isolation\n", 
    "#forest or robust covariance estimation to detect outliers.\n",
    "#Feature Selection: Consider selecting a subset of features that are most relevant for\n", 
    "#clustering. High-dimensional feature spaces can lead to increased computational complexity\n", 
    "#and noisy clusters. Choose features that capture the essential characteristics of the data.\n",
    "#Feature Scaling: Ensure that the features are properly scaled before clustering.\n", 
    "#DBSCAN is sensitive to the scale of features, so standardizing or normalizing the data can\n", 
    "#improve the clustering results.\n",
    "#Alternative Algorithms: If DBSCAN does not yield satisfactory results, consider trying\n", 
    "#alternative clustering algorithms such as K-means, hierarchical clustering, or spectral\n", 
    "#clustering. Each algorithm has its own strengths and weaknesses, so it's worth experimenting\n",
    "#with different approaches.\n",
    "#Domain Knowledge: Incorporate domain knowledge to guide the clustering process. Understanding\n", 
    "#the underlying properties of the data and the expected structure of the clusters can help in\n", 
    "#selecting appropriate algorithms and parameter settings.\n",
    "\n",
    "# from sklearn.cluster import DBSCAN\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# # Select relevant features (e.g., position and velocity measurements)\n",
    "# X = data[['ra', 'dec', 'pmra', 'pmdec']].values\n",
    "\n",
    "# # Initialize DBSCAN clustering algorithm\n",
    "# dbscan = DBSCAN(eps=0.5, min_samples=10)\n",
    "\n",
    "# # Fit the model to the scaled data\n",
    "# cluster_labels = dbscan.fit_predict(X)\n",
    "\n",
    "# # Visualize clusters\n",
    "# plt.figure(figsize=(8, 6))\n",
    "# plt.scatter(X[:, 0], X[:, 1], c=cluster_labels, cmap='viridis', s=10)\n",
    "# plt.xlabel('Right Ascension')\n",
    "# plt.ylabel('Declination')\n",
    "# plt.title('DBSCAN Clusters')\n",
    "# plt.colorbar(label='Cluster Label')\n",
    "# plt.show()\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Handle missing values by imputing with mean\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "X_imputed = imputer.fit_transform(X)\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_imputed)\n",
    "from sklearn.cluster import DBSCAN\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Initialize DBSCAN clustering algorithm\n",
    "dbscan = DBSCAN(eps=0.5, min_samples=10)\n",
    "\n",
    "# Fit the model to the scaled data\n",
    "cluster_labels = dbscan.fit_predict(X_scaled)\n",
    "\n",
    "# Visualize clusters\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(X_scaled[:, 0], X_scaled[:, 1], c=cluster_labels, cmap='viridis', s=10)\n",
    "plt.xlabel('Scaled Right Ascension')\n",
    "plt.ylabel('Scaled Declination')\n",
    "plt.title('DBSCAN Clusters')\n",
    "plt.colorbar(label='Cluster Label')\n",
    "plt.show()\n",
    "\n",
    "#Not great, I keep getting blocks of noise, its just using all the data and taking a long time to run,\n",
    "#I need to narrow it down much more\n", 
    "\n",
    "from sklearn.cluster import DBSCAN\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define the narrowed range of right ascension (RA) and declination (DEC)\n",
    "ra_min, ra_max = 265, 266  # Example narrowed range for RA\n", 
    "dec_min, dec_max = -54, -53.5  # Example narrowed range for DEC\n", 
    "\n",
    "# Filter data to the narrowed range\n",
    "filtered_data = data[(data['ra'] > ra_min) & (data['ra'] < ra_max) & (data['dec'] > dec_min) & (data['dec'] < dec_max)]\n",
    "\n",
    "# Select relevant features (e.g., position and velocity measurements)\n",
    "X = filtered_data[['ra', 'dec', 'pmra', 'pmdec']].values\n",
    "\n",
    "# Handle missing values by imputing with mean\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "X_imputed = imputer.fit_transform(X)\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_imputed)\n",
    "\n",
    "# Initialize DBSCAN clustering algorithm\n",
    "dbscan = DBSCAN(eps=0.5, min_samples=10)\n",
    "\n",
    "# Fit the model to the scaled data\n",
    "cluster_labels = dbscan.fit_predict(X_scaled)\n",
    "\n",
    "# Visualize clusters\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(X_scaled[:, 0], X_scaled[:, 1], c=cluster_labels, cmap='viridis', s=10)\n",
    "plt.xlabel('Scaled Right Ascension')\n",
    "plt.ylabel('Scaled Declination')\n",
    "plt.title('DBSCAN Clusters (Narrowed Range)')\n",
    "plt.colorbar(label='Cluster Label')\n",
    "plt.show()\n",
    "\n",
    "#If we can assume that NGC 6397 members are expected to have certain ranges of position and velocity measurements based on\n", 
    "#our previous observations, we can then evaluate if the clusters identified by the model contain stars that fall within the expected ranges.\n",
    "#A general approach to explore the properties of the clusters and assess their similarity to known NGC 6397 members includes the following\n",
    "\n",
    "#Cluster Characteristics: We compute the mean or median position and velocity measurements for each cluster identified by DBSCAN.\n",
    "import numpy as np\n",
    "\n",
    "# Compute mean or median position and velocity measurements for each cluster\n",
    "cluster_stats = []\n",
    "for label in np.unique(cluster_labels):\n",
    "    if label == -1:\n",
    "        continue  # Skip noise points\n",
    "    cluster_indices = np.where(cluster_labels == label)[0]\n",
    "    cluster_positions = X[cluster_indices, :2]  # RA and DEC\n",
    "    cluster_velocities = X[cluster_indices, 2:]  # PMRA and PMDEC\n",
    "    \n",
    "    # Compute mean or median position and velocity measurements\n",
    "    mean_position = np.mean(cluster_positions, axis=0)\n",
    "    mean_velocity = np.mean(cluster_velocities, axis=0)\n",
    "    \n",
    "    cluster_stats.append({\n",
    "        'label': label,\n",
    "        'mean_position': mean_position,\n",
    "        'mean_velocity': mean_velocity\n",
    "    })\n",
    "\n",
    "# Print cluster characteristics\n",
    "for cluster in cluster_stats:\n",
    "    print(f"Cluster {cluster['label']}:")\n",
    "    print(f"Mean Position (RA, DEC): {cluster['mean_position']}")\n",
    "    print(f"Mean Velocity (PMRA, PMDEC): {cluster['mean_velocity']}")\n",
    "    print()\n",
    "\n",
    "#Comparison with Known Properties: We can compare the computed characteristics of the clusters with the expected properties of\n", 
    "#NGC 6397 cluster members. This could involve comparing the clusters' position and velocity measurements to known ranges or\n", 
    "#distributions of NGC 6397 members.\n",
    "\n",
    "#Visual Inspection: We will then visualize the clusters on a sky map and velocity space plot to assess their spatial\n", 
    "#distribution and velocity patterns. This will provide insights into the clustering structure and identify any\n", 
    "#distinct subgroups within the clusters.\n",
    "# Visualize clusters on a sky map\n",
    "plt.figure(figsize=(10, 8))\n",
    "for cluster in cluster_stats:\n",
    "    cluster_indices = np.where(cluster_labels == cluster['label'])[0]\n",
    "    plt.scatter(X[cluster_indices, 0], X[cluster_indices, 1], label=f"Cluster {cluster['label']}")\n",
    "plt.xlabel('Right Ascension')\n",
    "plt.ylabel('Declination')\n",
    "plt.title('Clusters on Sky Map')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Visualize clusters in velocity space\n",
    "plt.figure(figsize=(8, 6))\n",
    "for cluster in cluster_stats:\n",
    "    cluster_indices = np.where(cluster_labels == cluster['label'])[0]\n",
    "    plt.scatter(X[cluster_indices, 2], X[cluster_indices, 3], label=f"Cluster {cluster['label']}")\n",
    "plt.xlabel('Proper Motion RA (mas/yr)')\n",
    "plt.ylabel('Proper Motion DEC (mas/yr)')\n",
    "plt.title('Clusters in Velocity Space')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "#Statistical Analysis: We can perform statistical tests or metrics (e.g., Kolmogorov-Smirnov test, Mahalanobis distance) to\n", 
    "#quantify the similarity between the clusters and known NGC 6397 members.\n",
    "\n",
    "from scipy.stats import ks_2samp\n",
    "\n",
    "# Define known properties of NGC 6397 cluster members (e.g., ranges of position and velocity measurements)\n",
    "# Example: Define ranges of RA, DEC, PMRA, and PMDEC based on observational data or literature\n",
    "ngc6397_ra_range = (265, 266)\n",
    "ngc6397_dec_range = (-54, -53.5)\n",
    "ngc6397_pmra_range = (-5, 5)  # Example range for proper motion in RA (mas/yr)\n",
    "ngc6397_pmdec_range = (-5, 5)  # Example range for proper motion in DEC (mas/yr)\n",
    "\n",
    "# Compute KS statistic and p-value for position measurements (RA and DEC)\n",
    "ra_ks_stat, ra_ks_pvalue = ks_2samp(filtered_data['ra'], ngc6397_ra_range)\n",
    "dec_ks_stat, dec_ks_pvalue = ks_2samp(filtered_data['dec'], ngc6397_dec_range)\n",
    "\n",
    "# Compute KS statistic and p-value for velocity measurements (PMRA and PMDEC)\n",
    "pmra_ks_stat, pmra_ks_pvalue = ks_2samp(filtered_data['pmra'], ngc6397_pmra_range)\n",
    "pmdec_ks_stat, pmdec_ks_pvalue = ks_2samp(filtered_data['pmdec'], ngc6397_pmdec_range)\n",
    "\n",
    "# Print KS statistics and p-values\n",
    "print("KS Test Results:")\n",
    "print(f"RA: KS Statistic = {ra_ks_stat}, p-value = {ra_ks_pvalue}")\n",
    "print(f"DEC: KS Statistic = {dec_ks_stat}, p-value = {dec_ks_pvalue}")\n",
    "print(f"PMRA: KS Statistic = {pmra_ks_stat}, p-value = {pmra_ks_pvalue}")\n",
    "print(f"PMDEC: KS Statistic = {pmdec_ks_stat}, p-value = {pmdec_ks_pvalue}")\n",
    "\n",
    "ISOCHRONES\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load data from CSV file\n",
    "data = pd.read_csv('data/NGC6397_iso.csv')\n",
    "\n",
    "# Plot the isochrone with color encoding for stellar phase\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.scatter(data['bp_rp'], data['Gaia_G_EDR3'], c=data['phase'], cmap='viridis', s=5)\n",
    "plt.colorbar(label='Stellar Phase')\n",
    "plt.xlabel('bp_rp')\n",
    "plt.ylabel('Gaia_G_EDR3 (phot_g_mean_mag)')\n",
    "plt.title('Isochrone of NGC 6397 with Stellar Phase Encoding')\n",
    "plt.gca().invert_yaxis()  # Invert y-axis to show brighter stars at the top\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load Gaia data\n",
    "gaia_data = pd.read_csv('data/gaia-NGC6397-neighborhood.csv')\n",
    "\n",
    "# Load isochrone data\n",
    "isochrone_data = pd.read_csv('data/NGC6397_iso.csv')\n",
    "\n",
    "# Load cluster members data\n",
    "cluster_members_data = pd.read_csv('data/NGC6397-1.dat', delim_whitespace=True, header=None, names=['ra', 'dec'])\n",
    "\n",
    "# Plot all Gaia data with the isochrone\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.scatter(gaia_data['ra'], gaia_data['dec'], s=1, label='Gaia Data')\n",
    "plt.scatter(isochrone_data['bp_rp'], isochrone_data['Gaia_G_EDR3'], c=isochrone_data['phase'], cmap='viridis', s=5, label='Isochrone')\n",
    "plt.xlabel('BP-RP')\n",
    "plt.ylabel('Gaia_G_EDR3 (phot_g_mean_mag)')\n",
    "plt.title('Gaia Data with Isochrone')\n",
    "plt.legend()\n",
    "plt.gca().invert_yaxis()  # Invert y-axis to match Gaia magnitude scale\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Plot cluster members with the isochrone\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.scatter(cluster_members_data['ra'], cluster_members_data['dec'], s=1, label='Cluster Members')\n",
    "plt.scatter(isochrone_data['bp_rp'], isochrone_data['Gaia_G_EDR3'], c=isochrone_data['phase'], cmap='viridis', s=5, label='Isochrone')\n",
    "plt.xlabel('RA')\n",
    "plt.ylabel('DEC')\n",
    "plt.title('Cluster Members with Isochrone')\n",
    "plt.legend()\n",
    "plt.gca().invert_yaxis()  # Invert y-axis to match Gaia magnitude scale\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "#I know this graph looks bad, but I cant find a way to make it better without isolating the data, which i guess I could do, hmm\n",
    "\n",
    "#To argue whether new cluster candidates are viable we first plot the H-R diagram using the Gaia data and\n", 
    "#overlay the isochrone. We then check if the new cluster candidates fall within the region predicted by the\n",
    "#isochrone. If they align well with the expected stellar evolution tracks, it suggests that they could be genuine cluster members.\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load Gaia data\n",
    "gaia_data = pd.read_csv('data/gaia-NGC6397-neighborhood.csv')\n",
    "\n",
    "# Load isochrone data\n",
    "isochrone_data = pd.read_csv('data/NGC6397_iso.csv')\n",
    "\n",
    "# Plot the H-R diagram with Gaia data and overlay the isochrone\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.scatter(gaia_data['bp_rp'], gaia_data['phot_g_mean_mag'], s=1, label='Gaia Data')\n",
    "plt.scatter(isochrone_data['bp_rp'], isochrone_data['Gaia_G_EDR3'], c=isochrone_data['phase'], cmap='viridis', s=5, label='Isochrone')\n",
    "plt.xlabel('BP-RP')\n",
    "plt.ylabel('Gaia_G_EDR3 (phot_g_mean_mag)')\n",
    "plt.title('H-R Diagram with Isochrone')\n",
    "plt.legend()\n",
    "plt.gca().invert_yaxis()  # Invert y-axis to match magnitude scale\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "#Next we can create a Color Magnitude Diagram using Gaia photometry and compare it with the isochrone\n", 
    "#to check if the new candidates coincide with the expected positions. This isnt really necessary and the same\n",
    "#plot as above\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.scatter(gaia_data['bp_rp'], gaia_data['phot_g_mean_mag'], s=1, label='Gaia Data')\n",
    "plt.scatter(isochrone_data['bp_rp'], isochrone_data['Gaia_G_EDR3'], c=isochrone_data['phase'], cmap='viridis', s=5, label='Isochrone')\n",
    "plt.xlabel('BP-RP')\n",
    "plt.ylabel('Gaia_G_EDR3 (phot_g_mean_mag)')\n",
    "plt.title('Color-Magnitude Diagram (CMD) with Isochrone')\n",
    "plt.legend()\n",
    "plt.gca().invert_yaxis()  # Invert y-axis to match magnitude scale\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# This is all the code with a bunch of troubleshooting code to try and answer this question, so I just made another code box below to just have\n", 
    "#the clean code\n",
    "#import pandas as pd\n",
    "# from sklearn.impute import SimpleImputer\n",
    "\n",
    "# # Load data\n",
    "# data = pd.read_csv('processed_data.csv')\n",
    "\n",
    "# # Check for missing values\n",
    "# print("Missing values before imputation:")\n",
    "# print(data.isnull().sum())\n",
    "\n",
    "# # Impute missing values\n",
    "# imputer = SimpleImputer(strategy='mean')\n",
    "# data_imputed = pd.DataFrame(imputer.fit_transform(data), columns=data.columns)\n",
    "\n",
    "# # Check for missing values after imputation\n",
    "# print("\nMissing values after imputation:")\n",
    "# print(data_imputed.isnull().sum())\n",
    "\n",
    "# # Define features and target variable\n",
    "# X = data_imputed[['ra', 'dec', 'pmra', 'pmdec', 'bp_rp', 'phot_g_mean_mag']].values\n",
    "# # y = data_imputed['target'].values\n",
    "\n",
    "# print(np.isinf(X).sum(axis=0))\n",
    "# # import pandas as pd\n",
    "#  # Initialize and fit KMeans clustering model\n",
    "\n",
    "# # Get cluster labels\n",
    "# # Load Gaia data\n",
    "# gaia_data = pd.read_csv('data/gaia-NGC6397-neighborhood.csv')\n",
    "\n",
    "# # Calculate color (BP-RP) and brightness (phot_g_mean_mag)\n",
    "# gaia_data['bp_rp'] = gaia_data['phot_bp_mean_mag'] - gaia_data['phot_rp_mean_mag']\n",
    "\n",
    "# # Combine relevant features into a DataFrame\n",
    "# processed_data = gaia_data[['ra', 'dec', 'pmra', 'pmdec', 'bp_rp', 'phot_g_mean_mag']]\n",
    "\n",
    "# # Save processed data to a CSV file\n",
    "# processed_data.to_csv('processed_data.csv', index=False)\n",
    "\n",
    "# # Load processed data\n",
    "# data = pd.read_csv('processed_data.csv')\n",
    "\n",
    "# # Define features\n",
    "# X = data[['ra', 'dec', 'pmra', 'pmdec', 'bp_rp', 'phot_g_mean_mag']].values\n",
    "# # Use unsupervised learning or clustering algorithms (e.g., KMeans, DBSCAN) to find patterns in the data\n",
    "# # For example:\n",
    "# from sklearn.cluster import KMeans\n",
    "\n",
    "# # Define the number of clusters (you may need to choose this based on domain knowledge or other criteria)\n",
    "# n_clusters = 2\n",
    "\n",
    "# # Initialize and fit KMeans clustering model\n",
    "# #n_clusters to 2\n",
    "# kmeans = KMeans(n_clusters=n_clusters)\n",
    "# print("Missing values in X:")\n",
    "# print(np.isnan(X).sum())\n",
    "\n",
    "# kmeans.fit(X)\n",
    "\n",
    "# # Get cluster labels\n",
    "# cluster_labels = kmeans.labels_\n",
    "\n",
    "# # import pandas as pd\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# #Load data\n",
    "# data = pd.read_csv('processed_data.csv')\n",  
    "\n",
    "# # Define features and target variable\n",
    "# X = data[['ra', 'dec', 'pmra', 'pmdec', 'bp_rp', 'phot_g_mean_mag']].values\n",
    "# y = data['target'].values\n",
    "\n",
    "# # Split data into train and test sets\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# # Initialize and train classifier\n",
    "# classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "# classifier.fit(X_train, y_train)\n",
    "\n",
    "# # Make predictions\n",
    "# y_pred = classifier.predict(X_test)\n",
    "\n",
    "# # Evaluate performance\n",
    "# accuracy = accuracy_score(y_test, y_pred)\n",
    "# report = classification_report(y_test, y_pred)\n",
    "\n",
    "# print("Accuracy:", accuracy)\n",
    "# print("Classification Report:")\n",
    "# print(report)\n",
    "\n",
    "#Well nvm, I thought I got it working, but nope, still got troubleshooting stuff to do\n",
    "import pandas as pd\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Load data\n",
    "data = pd.read_csv('processed_data.csv')\n", 
    "\n",
    "# # Check for missing values\n",
    "# print("Missing values before imputation:")\n",
    "# print(data.isnull().sum())\n",
    "\n",
    "# Impute missing values\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "data_imputed = pd.DataFrame(imputer.fit_transform(data), columns=data.columns)\n",
    "\n",
    "# # Assuming 'cluster_member' needs to be created based on some criteria\n",
    "# if 'cluster_member' in data_imputed.columns:\n",
    "#     data_imputed['target'] = (data_imputed['cluster_member'] == 1).astype(int)\n",
    "# else:\n",
    "#     print("Error: 'cluster_member' column not found in the DataFrame.")\n",
    "\n",
    "# Define features and target variable\n",
    "X = data_imputed[['ra', 'dec', 'pmra', 'pmdec', 'bp_rp', 'phot_g_mean_mag']].values\n",
    "\n",
    "data_imputed['target'] = (data_imputed['pmra'] == 1).astype(int)\n",
    "y = data_imputed['target'].values\n",
    "\n",
    "# Check for missing values after imputation\n",
    "print("\nMissing values after imputation:")\n",
    "print(data_imputed.isnull().sum())\n",
    "\n",
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize and train classifier\n",
    "classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "# Evaluate performance\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "print("Accuracy:", accuracy)\n",
    "print("Classification Report:")\n",
    "print(report)\n",
    "#I think it works now, maybe, imma be honest, I worked on this for like so many hours, and im just happy theres no error\n",

   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
